{
  "PostValue": {
    "post_id": "jivMzobjBqEYSyrKy",
    "value_ea": 7,
    "value_humanity": 6,
    "explanation": "This post advances a potentially high-leverage institutional reform that speaks directly to core EA/longtermist concerns (collective decision-making on existential risks). The argument has plausible technical foundations (random sampling, CIR evidence) and presents a cheap-to-test, scalable intervention with very large upside if it improves policy on climate, pandemics, or AI. That makes it strategically important for the EA community to investigate and pilot further. However, the proposal is also substantially speculative: political feasibility, scaling, facilitator influence, and real-world robustness to capture/coercion are unresolved and could greatly reduce impact. For general humanity the upside is large (could materially improve governance), but the probability of wide, rapid adoption and the many practical risks make its expected near-term importance somewhat lower. Overall, a promising, neglected target worth research and small pilots, but not yet a foundational or guaranteed-win idea."
  },
  "PostRobustness": {
    "post_id": "jivMzobjBqEYSyrKy",
    "robustness_score": 3,
    "actionable_feedback": "1) Overstated/statistical-logic claim about \u201c40 people\u201d \u2014 The post presents the 40-person result as a general, almost magical fact without spelling out the assumptions. That number only holds under narrow statistical assumptions (random sampling, IID preferences, one-dimensional decision, negligible measurement error, identical deliberative treatment for the whole population, etc.). Deliberation itself changes preferences in non\u2011trivial and non\u2011IID ways (framing effects, facilitator influence, social conformity, charismatic speakers), and real-world heterogeneity across subpopulations can make small samples systematically biased. Actionable fixes: (a) Tone down the blanket 40-person claim and replace it with a clear statement of assumptions and failure modes; (b) add citations to deliberative-polling and citizens\u2019 assembly literature (e.g., Fishkin, Dryzek, OECD reviews) and to any simulations or sensitivity analyses you ran; (c) include one short paragraph or appendix summarizing sensitivity analyses (sample size vs heterogeneity, framing bias, correlated errors) or link to the math with these caveats made explicit.\n\n2) Underestimates other capture/manipulation vectors beyond simple bribery \u2014 The rebuttal to capture focuses narrowly on bribing jurors and assumes secret ballots + size fixes everything. That overlooks cheaper and more plausible attack surfaces: controlling expert selection and testimony, framing agenda, corrupting facilitators/organizers, coercing or influencing recruitment (e.g., via targeted exemptions), coordinated social pressure, and misinformation campaigns aimed at the small sample. Actionable fixes: (a) Add a realistic threat model listing potential attack vectors and their estimated costs/risks; (b) propose concrete mitigations you would adopt (transparent/randomized expert selection, publicly archived transcripts/videos, independent auditors, mixed recruitment mechanisms, legal penalties, rotation of facilitators); (c) if possible, quantify or simulate how these mitigations change the cost-benefit of attacks rather than relying on jury size alone.\n\n3) Legitimacy, legal feasibility, and the x-risk claim need tighter linking \u2014 The post asserts large existential-payoff multipliers but doesn\u2019t show the causal pathways (how EBJ produces better global coordination on AI/biotech/climate) nor address likely political/legal backlash (constitutional concerns, accusations of elitism/populist delegitimization). Actionable fixes: (a) Add a concise causal map explaining how EBJ at city/state levels scales to national/international policy improvements and reduces x-risk, with plausible quantitative levers (e.g., faster adoption of technical regulations, higher-quality expert-informed votes on key statutes); (b) acknowledge legal/legitimacy barriers and outline explicit staged pilots (advisory \u2192 hybrid \u2192 binding), metrics for success, and communication strategies to build public trust; (c) consider including comparative evidence from larger pilots (Ireland, British Columbia citizens\u2019 assembly, Deliberative Polling outcomes) and concrete metrics you\u2019d track (policy accuracy proxies, public acceptance, resistance to manipulation).",
    "improvement_potential": "The feedback pinpoints major, substantive weaknesses that could embarrass the author (overstating the \u201840 people\u2019 result, relying on jury size/secret ballot as a catch\u2011all against capture, and a thin causal link from EBJ to existential\u2011risk reduction). It gives concrete, actionable fixes (add assumptions/caveats and citations, present a realistic threat model and mitigations, and map causal pathways with staged pilots and metrics) that would substantially strengthen credibility without necessarily bloating the post."
  },
  "PostAuthorAura": {
    "post_id": "jivMzobjBqEYSyrKy",
    "author_fame_ea": 1,
    "author_fame_humanity": 1,
    "explanation": "I find no evidence that 'ClayShentrup' is a recognized figure in the EA/rationalist community or the wider public: no notable publications, conference appearances, or widely cited posts under that name up to my 2024-06 cutoff. The handle may be a minor/anonymous pseudonym with little or no public footprint."
  },
  "PostClarity": {
    "post_id": "jivMzobjBqEYSyrKy",
    "clarity_score": 8,
    "explanation": "Overall the post is clear, well-structured, and easy to follow. Headings and a logical flow (problem \u2192 mathematical/statistical solution \u2192 philosophy \u2192 costs/benefits \u2192 objections \u2192 implementation \u2192 call to action) make the argument accessible, and concrete examples (Oregon CIR) and rough cost/benefit numbers strengthen persuasiveness. Weaknesses: a few key claims (the \"40-person\" statistic, existential-risk multipliers, and some cost/benefit assumptions) are asserted with limited on-page justification, some sections are a bit repetitive or rhetorically grandiose, and a tighter presentation or more citations would improve precision and conciseness."
  },
  "PostNovelty": {
    "post_id": "jivMzobjBqEYSyrKy",
    "novelty_ea": 4,
    "novelty_humanity": 6,
    "explanation": "Most of the core ideas\u2014sortition/citizen juries, Citizens\u2019 Initiative Review, deliberative mini-publics, using random samples to approximate public opinion, and arguments about epistemic limits of mass democracy\u2014are well established in political theory and practice and have been discussed in EA-adjacent circles. The post\u2019s original contributions are mainly (a) packaging these into a specific EA-target pitch (arguing high EV vs. existential risk), (b) emphasizing the 40-person statistical claim as a strong formal justification for mini\u2011publics, and (c) the speculative extension of secret ballots for officials. Those syntheses and the EA framing have some novelty for general readers, but are only moderately novel for EA Forum readership familiar with governance, deliberative democracy, and sortition literature."
  },
  "PostInferentialSupport": {
    "post_id": "jivMzobjBqEYSyrKy",
    "reasoning_quality": 6,
    "evidence_quality": 4,
    "overall_support": 5,
    "explanation": "Strengths: The post presents a clear, logically structured argument: mass deliberation is infeasible, random sampling offers a statistical fix, and deliberative citizen panels (e.g. Oregon CIR) show citizens can make useful judgements when supported. The author correctly highlights important barriers (attention economics, epistemic bubbles, adversarial actors) and offers plausible mechanisms (random selection, secret ballots, larger panels) to mitigate capture and misinformation. Weaknesses: Several key steps rely on strong assumptions that are not demonstrated: that small randomly selected juries reliably reproduce the population decision under realistic deliberation dynamics; that deliberation reliably improves decision quality on complex, technical issues; and that scaling from advisory pilots (CIR) to binding, wide-ranging EBJ will be politically and institutionally feasible. Empirical evidence is limited and selective \u2014 CIR-style programs support feasibility and public trust but do not establish improved policy outcomes at scale or the claimed existential-risk-reduction benefits. Cost-benefit and bribery-resistance calculations are plausible but underspecified and sensitive to assumptions. Overall: an interesting, coherent proposal with some empirical backing, but substantial evidentiary and theoretical gaps remain before the strong claims (high EV, tamper-proof, scalable replacement for voting) are well-supported."
  },
  "PostExternalValidation": {
    "post_id": "jivMzobjBqEYSyrKy",
    "emperical_claim_validation_score": 4,
    "validation_notes": "Mixed but leaning inaccurate. Several of the post\u2019s central empirical claims are contradicted or unsupported by available evidence: public concern about AI and support for pandemic-preparedness funding are *much* higher than the post\u2019s quoted figures (contradicted by Pew, Gallup, KFF and other polls); the claim that only ~3% of Americans see AI risk as a critical threat and that 41% oppose more pandemic preparedness funding are not supported. The author\u2019s descriptive claims about Citizens\u2019 Initiative Review (CIR) \u2014 origin in Oregon, demonstrated effectiveness in deliberation, and per-panel costs in the low hundreds of thousands \u2014 are well supported by Healthy Democracy and peer-reviewed research (Gastil et al. 2014). Claims about approval-voting\u2019s \u201cremarkable success\u201d are partly true (a few U.S. cities implemented it, e.g., St. Louis and Fargo) but the movement\u2019s adoption remains limited and has faced reversals (state bans). The statistical claims about needing \u201conly ~40 people\u201d to reliably reproduce whole-population outcomes are overstated: small juries can sometimes reflect majority preference but margin-of-error and sampling issues mean the result depends heavily on the underlying population split and voting rule; ElectionByJury\u2019s own page contains a bespoke model but the general statistical claim lacks the necessary caveats. Cost/benefit figures and expected % improvements in decision quality are speculative and lack empirical grounding. Summary: some institutional claims (CIR, CES involvement, limited approval voting adoption) are supported; many quantitative claims about public opinion, sampling certainty, and ROI are exaggerated or inadequately sourced.",
    "sources": [
      "Pew Research Center \u2014 \"What the data says about Americans\u2019 views of artificial intelligence\", Nov 21, 2023",
      "Gallup / Bentley-Gallup Business in Society Report (survey reporting on Americans' views of AI), Apr\u2013May 2024",
      "YouGov reporting on American concern about AI (2025 surveys)",
      "Healthcare Ready \u2014 National Preparedness Poll (March 2020) showing strong public support for preparedness",
      "BIO / Healthcare Ready / Wakefield Research press release \u2014 March 30, 2023 (poll showing majority support for public health preparedness)",
      "KFF \u2014 Health Tracking Poll: The Public\u2019s Views on Global Health and USAID (Feb 2025)",
      "Healthy Democracy \u2014 Citizens\u2019 Initiative Review (CIR) project page (history, process, costs)",
      "Gastil, J., Richards, R., & Knobloch, K., \"Vicarious Deliberation: How the Oregon Citizens' Initiative Review Influenced Deliberation in Mass Elections\", International Journal of Communication, 2014",
      "ElectionByJury.org \u2014 \"Jury Size\" page (author\u2019s own statistical model and claims)",
      "Ballotpedia \u2014 \"Approval voting\" (status of adoption; St. Louis, Fargo etc.; state-level changes) (April 2025 snapshot)",
      "Center for Election Science \u2014 organization page / Wikipedia entry (founders include Clay Shentrup; role in Fargo and St. Louis campaigns)",
      "Associated Press / ABC / other reporting on North Dakota action affecting Fargo's approval voting (coverage of bans and reversals, 2024\u20132025)",
      "Wikipedia \u2014 \"Manhattan Project\" (personnel and scale) and \"Hanford Engineer Works\" (site man-hours) \u2014 to illustrate that the post\u2019s Manhattan-Project comparison lacks a clear authoritative person-hours citation",
      "Standard sampling/margin-of-error statistics (textbook formula for margin of error / confidence intervals) \u2014 demonstrates that n=40 implies ~\u00b115% worst-case margin for simple proportions"
    ]
  }
}