{
  "PostValue": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "value_ea": 6,
    "value_humanity": 3,
    "explanation": "Useful, pragmatic methodological contribution for the EA/forecasting community: framing conditional questions as a way to elicit and compare experts' latent models is likely to improve judgment elicitation on hard, high\u2011stakes topics (e.g., AI timelines, disruptive tech) and could materially improve some decisions and debates. It is incremental rather than foundational \u2014 promising and practically valuable but not a paradigm shift \u2014 and evidence so far is limited (small pilots, many similar efforts exist). For general humanity the impact is indirect and modest: better elicitation can improve policy/forecast quality, but benefits are diffuse and contingent on adoption."
  },
  "PostRobustness": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "robustness_score": 3,
    "actionable_feedback": "1) You understate the behavioural and incentive problems in eliciting conditional probabilities. The post assumes experts will happily and coherently provide P(U), P(C), P(U|C) and P(U|\u00acC) and that inconsistent answers are simply \u201cinformation.\u201d In reality people are badly calibrated, incoherent, suffer motivated reasoning, and may strategically answer. Actionable fixes: acknowledge these failure modes, cite structured\u2011expert\u2011judgment literature (e.g. Cooke, SHELF), and describe concrete mitigations you plan or recommend \u2014 e.g. coherence checks and automated feedback, proper scoring rules tied to incentives, forced\u2011choice/elicitation designs that reduce anchoring, and calibration training or debiasing prompts. Without this, the technique risks producing noisy or systematically biased \u201cmodels.\u201d\n\n2) The mutual\u2011information math/implementation needs more care and clearer exposition. Your code/description glosses over (a) the base of the logarithm and units (bits vs nats), (b) numerical instability at 0/1 probabilities and how you\u2019ll handle boundary cases, and (c) conceptual ambiguities: high mutual information can reflect large conditional shifts due to extreme but implausible antecedents rather than genuine causal importance. Actionable fixes: (i) show the derivation that maps the elicited quantities to a correct MI formula (and pick/justify a log base), (ii) add smoothing or regularization for 0/1 reports and rejection rules for trivial/overlapping antecedents, and (iii) discuss alternative metrics (e.g. expected value of perfect information, KL divergence, or simply effect size P(U|C)\u2212P(U)) and when you\u2019d prefer each.\n\n3) You gloss over the hard problem of mapping different people\u2019s \"primitives\" into a comparable parameterization. Asking people to forecast on each other\u2019s trees is promising but underdeveloped: primitives may be incommensurate, translations can change meaning, and the elicitation cost grows quickly with tree size. Actionable fixes: add a short section on practical procedures for mapping/aligning primitives (e.g. canonical definitions, unitization, anchoring examples), adaptive question selection to minimize burden (active learning / VOI-based selection), and an explicit validation plan (simulations, held\u2011out prediction tasks, or pre-registered experiments) so readers know how you\u2019ll test whether the method actually improves forecast accuracy or interpretability.",
    "improvement_potential": "The feedback identifies several substantial, actionable gaps that would materially improve the post: (1) behavioral/incentive failures and structured expert\u2011judgment literature that the post currently skips over (a plausible 'own goal' given the reliance on elicited probabilities); (2) concrete math/implementation issues (log base mismatch, 0/1 instability, and conceptual limits of MI) that are embarrassingly easy to fix or at least require explicit caveats; and (3) practical problems in translating different people\u2019s primitives and scaling elicitation, plus concrete mitigations (VOI\u2011based question selection, validation plans). Addressing these would shore up the method\u2019s credibility; they\u2019re critical but don\u2019t imply the thesis is wrong, only that key methodological weaknesses need to be acknowledged and remedied."
  },
  "PostAuthorAura": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "author_fame_ea": 1,
    "author_fame_humanity": 1,
    "explanation": "As of my 2024-06 knowledge cutoff there is no clear evidence that a widely recognized EA/rationalist figure named Molly Hickman exists. I cannot find prominent EA Forum/LessWrong posts, major EA org affiliation, high-profile talks, or notable academic/publication citations under that name; she appears to be unknown or a minor/pseudonymous online author."
  },
  "PostClarity": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "clarity_score": 8,
    "explanation": "Overall the post is well structured and readable: clear motivation, logical flow (problem \u2192 method \u2192 math \u2192 pilot), and useful concrete examples and code. It communicates the core idea \u2014 using conditional questions to elicit and compare experts' implicit models \u2014 in a compelling way and gives practical detail for implementation. Weaknesses: it assumes some forecasting jargon/technical background (VOI, mutual information, crux/primitives) so less technical readers may need more definitions or a simpler summary; the math/code section is dense and could be signposted as optional earlier. Tightening a few long paragraphs and defining key terms up front would make it slightly more accessible without losing nuance."
  },
  "PostNovelty": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "novelty_ea": 3,
    "novelty_humanity": 7,
    "explanation": "Most of the core techniques (eliciting conditional probabilities, decomposing forecasts into cruxes, using mutual information / VOI to rank antecedents, comparing people\u2019s decomposition trees) are already known and actively used within the forecasting/EA community (FRI, Metaculus, GJ, Tetlockian work). The post\u2019s modestly novel contributions are its framing \u2014 explicitly calling conditional forecasting a parameterization of fuzzy models, emphasising \u2018primitives\u2019 and cross\u2011forecasting on each other\u2019s trees, and the practical demonstration/experiments (fine\u2011tuned GPT crux generation, Manifest session). Those elements make it reasonably fresh to a general audience but fairly familiar to experienced EA/forecasting readers."
  },
  "PostInferentialSupport": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "reasoning_quality": 6,
    "evidence_quality": 3,
    "overall_support": 5,
    "explanation": "Strengths: The post presents a clear, coherent conceptual argument for using conditional forecasts (cruxes) and mutual-information-style metrics to surface and compare experts' implicit models. The framing (predictability ladder, primitives, comparing decompositions) is sensible and the math for scoring cruxes is appropriate and linked to established VOI/information-theoretic ideas. Weaknesses: The piece is largely exploratory and prescriptive rather than empirical. Evidence is thin \u2014 a small, informal Manifest pilot and a few citations to related forecasting literature \u2014 with no rigorous trials showing the approach improves calibration, accuracy, or decision-relevant model fidelity. Important practical issues are not fully addressed (elicitation biases, inconsistency handling beyond 'treat as signal', multi-variable dependencies beyond pairwise MI, cognitive cost, and generalizability). Overall the idea is plausible and reasonably argued, but under-supported by empirical evidence."
  },
  "PostExternalValidation": {
    "post_id": "Zniat3sPo5FKfdhpf",
    "emperical_claim_validation_score": 8,
    "validation_notes": "Most major empirical claims in the post are well supported by public literature and reproducible artifacts. Evidence that trained/generalist forecasters (e.g., Good Judgment Project / \u201csuperforecasters\u201d) can outperform professional intelligence analysts and many domain experts in geopolitical forecasting is well documented (Mellers et al. 2014/2015; Good Judgment Project summaries). The Forecasting Research Institute\u2019s methods (conditional trees / VOI) and code (voivod) are publicly available and match the post\u2019s description; FRI\u2019s adversarial-collaboration report and Conditional Trees case study corroborate claims about using conditional questions and VOI metrics. Citations the author lists about scoring rules (Roulston & Smith 2002; Br\u00f6cker & Smith 2007) accurately reflect debates over Brier vs. information/log scores \u2014 the literature shows tradeoffs rather than a simple \u201cBrier is worthless\u201d verdict. Some claims are inherently qualitative or anecdotal and cannot be independently verified from public sources: specifically, the small Manifest 2023 \u201cGood Questions Tournament\u201d experiment and the claim that a finetuned GPT-3.5 produced cruxes judged more informative (these may be true but are unpublished/insufficiently documented externally). Also, the literature shows nuance: experts sometimes outperform forecasters on certain long-range or specialist tasks (see Tetlock/Karvetski et al. on slow\u2011motion variables), so the blanket phrasing that \u201ctop forecasters have better understanding than domain experts\u201d should be qualified. Overall: well-supported with some caveats (unpublished/anoscdotal experiment, and needed nuance about where experts vs. forecasters have advantages).",
    "sources": [
      "Good Judgment / Superforecasters \u2014 'The Superforecasters\u2019 Track Record' (GoodJudgment.com) \u2014 https://goodjudgment.com/resources/the-superforecasters-track-record/ (summary of IARPA ACE results and comparisons to analysts).",
      "Mellers, B., et al. (2014). 'Psychological strategies for winning a geopolitical forecasting tournament.' Psychological Science. DOI:10.1177/0956797614524255 (experimental evidence: training, teaming, tracking improved forecasting accuracy).",
      "Mellers, B., et al. (2015). 'The psychology of intelligence analysis: drivers of prediction accuracy in world politics.' Journal of Experimental Psychology: Applied. (drivers of forecaster performance; predictors like cognitive ability, training, deliberation).",
      "Tetlock, P. E. & Karvetski, C., Satop\u00e4\u00e4, V., Chen, K. (2023/2024). 'Long\u2011range subjective\u2011probability forecasts of slow\u2011motion variables in world politics' (Futures & Foresight Science) \u2014 shows specialists sometimes beat generalists on some long\u2011range, domain\u2011specific tasks.",
      "Forecasting Research Institute \u2014 'Roots of Disagreement on AI Risk: Exploring the Potential and Pitfalls of Adversarial Collaboration' (FRI page & report) \u2014 https://forecastingresearch.org/ai-adversarial-collaboration and FRI news/results pages (describes the adversarial collaboration, sample sizes, results).",
      "Forecasting Research Institute GitHub \u2014 'adversarial-collab' replication repo and 'voivod' package (VOI/VOD code): https://github.com/forecastingresearch/adversarial-collab and https://github.com/forecastingresearch/voivod (public code implementing VOI metrics).",
      "FRI Conditional Trees / AI Conditional Trees case study (report + EA Forum summary): 'Conditional Trees: A Method for Generating Informative Questions about Complex Topics' and FRI pages \u2014 https://forecastingresearch.org/ai-conditional-trees and EA Forum summary: https://forum.effectivealtruism.org/posts/iMmpeCmfBk9sm6aLJ/conditional-trees-generating-informative-forecasting (describes generation of 75 questions and VOI comparisons).",
      "Roulston, M. & Smith, L. A. (2002). 'Evaluating Probabilistic Forecasts Using Information Theory.' Monthly Weather Review. DOI:10.1175/1520-0493(2002)130<1653:EPFUIT>2.0.CO;2 (advocates log/ignorance score and shows differences vs. Brier).",
      "Br\u00f6cker, J. & Smith, L. A. (2007). 'Scoring Probabilistic Forecasts: The Importance of Being Proper.' Weather and Forecasting. (discussion of propriety and locality of scoring rules).",
      "Manifest conference (Manifold) \u2014 event pages describing Manifest 2023 and 2024 (conference where the author says they ran a small session): https://manifest.is/ and historical info on Manifest 2023.",
      "Metaculus 'About' and team page (shows Molly Hickman as Technical Product Manager) and Molly Hickman public profiles (EA Forum user page / personal site) \u2014 https://www.metaculus.com/about/ and https://forum.effectivealtruism.org/users/molly-hickman-1 and https://hickman-santini.github.io/ (confirms affiliations mentioned in the post)."
    ]
  }
}