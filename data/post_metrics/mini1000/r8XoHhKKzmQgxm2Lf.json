{
  "PostValue": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "value_ea": 7,
    "value_humanity": 2,
    "explanation": "Useful, fairly high-impact empirical work for EA movement planners and orgs: it identifies which outreach channels scale (notably 80,000 Hours and personal contacts), demographic differences in recruitment, and how much new members come through active vs. passive outreach. That makes it load-bearing for outreach/resource-allocation decisions but not foundational to EA\u2019s core moral or technical claims; errors would mainly risk misdirected recruitment strategy rather than catastrophic consequences. Very limited relevance for the general public beyond social-movement or communications researchers."
  },
  "PostRobustness": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "robustness_score": 3,
    "actionable_feedback": "1) Understate / under-correct for sampling/referral bias \u2014 make this limitation much clearer and (ideally) adjust for it. A large fraction of respondents were recruited via EA channels (80k, Astral Codex Ten, direct email, etc.), which makes the observed shares for those sources upwardly biased. You already ran referral-exclusion checks, which is good, but readers will reasonably ask for either (a) reweighted estimates (inverse-probability or post-stratification by referral source) so reported percentages better reflect the broader EA population, or (b) clearer statements that the headline percentages are conditional on the sample and may substantially overstate the real-world importance of organizational channels. Actionable: (i) add reweighted numbers (or at least bounds) and/or (ii) move the unadjusted percentages into a subsection titled \u201csample-conditional estimates\u201d and foreground the adjusted/sensitivity results in the summary.  \n\n2) Active vs passive outreach coding is subjective and likely drives the \u201c~55% outreach\u201d headline \u2014 show reliability and do sensitivity analyses. You note grey areas, but readers will reasonably infer that this coding choice materially affects conclusions. Actionable: (i) report inter-rater reliability (e.g., Cohen\u2019s kappa or % agreement) for the outreach coding; (ii) provide one or two sensitivity analyses using alternative, transparent rules (e.g., classify borderline cases as non-outreach, or count \u201cfriend referring an EA resource\u201d as outreach) and report the resulting range for the % due to outreach; (iii) include a few example responses for each coding category in an appendix so readers can judge the classification.  \n\n3) Avoid causal language and improve statistical robustness (multiple comparisons / confounding). The post sometimes reads as implying that particular channels \u201chelp\u201d people get involved rather than being correlated with who the respondents are. Also you report many subgroup comparisons with p-values near 5% without correction. Actionable: (i) soften causal wording throughout (e.g., use \u201cassociated with\u201d rather than \u201cimportant for\u201d when appropriate); (ii) either apply a multiple-comparisons correction (or flag which results survive such corrections) or emphasize effect sizes and confidence intervals rather than isolated p<.05 claims; (iii) consider running simple multivariate regressions (e.g., logistic regressions predicting selecting a source as first-heard or important, controlling for referral source, cohort, gender, race, engagement level) to show which associations remain after adjusting for obvious confounders, and summarize key adjusted associations in the main text or appendix.",
    "improvement_potential": "Targets three key methodological weaknesses (sample/referral bias, subjective coding of outreach, and over-strong causal/statistical claims). The authors partly addressed some of these (referral exclusions, noting grey areas) but the recommendations (reweighting or foregrounding adjusted estimates, reporting inter-rater reliability and sensitivity checks for outreach coding, and using cautious language/multiple-comparisons corrections or adjusted regressions) would materially increase credibility without massively lengthening the post. These are important, actionable, and feasible improvements."
  },
  "PostAuthorAura": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "author_fame_ea": 1,
    "author_fame_humanity": 1,
    "explanation": "I am not aware of a notable EA/rationalist figure using the name David_Moss (and the name David Moss is common). No prominent EA writings, talks, or community roles under that exact handle are known to me. If you can supply a link, bio, or sample work, I can reassess more accurately."
  },
  "PostClarity": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "clarity_score": 8,
    "explanation": "Strengths: The post is well structured (summary, introduction, clear subsections, appendices) and uses concrete statistics and subgroup comparisons, which makes its claims easy to verify. Definitions and caveats (e.g., coding choices, engagement levels, referral robustness checks) are provided, and visuals are referenced to support the text. Weaknesses: It is long and sometimes repetitive, with many similar percentage statements that could be summarized to improve scan-ability. A few terms and distinctions (e.g., active vs. passive outreach, cohort/engagement framing) could be signposted more simply for non-expert readers. The post reports results clearly but could state higher-level takeaways or implications more explicitly and trim redundant detail to improve conciseness."
  },
  "PostNovelty": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "novelty_ea": 2,
    "novelty_humanity": 4,
    "explanation": "For EA readers this is low-novelty: it is an incremental, well-executed update on a long-running EA Survey series (2014\u20132022) and mostly confirms expected trends (80,000 Hours rising, LessWrong declining, personal contacts important) and demographic splits. The mildly novel bits are the active vs. passive outreach coding, the detailed cohort/robustness checks, and some specific subgroup patterns (e.g. 80k importance for non-White respondents), but these are refinements rather than original ideas. For the general public the findings are moderately novel: the concrete quantification of how people discover and become involved in EA, and the shift toward 80,000 Hours and organized outreach, would be new information to many non\u2011EA readers."
  },
  "PostInferentialSupport": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "reasoning_quality": 7,
    "evidence_quality": 6,
    "overall_support": 6,
    "explanation": "Strengths: The post is well-structured and cautious, reports descriptive results clearly, uses open-ended coding, subgroup analyses, longitudinal comparisons, and performs useful robustness checks (e.g., excluding referral sources). Authors acknowledge limitations and avoid strong causal claims. Weaknesses: The evidence is survey-based and subject to sampling/referral bias, recall and self-reporting errors, coding subjectivity (active vs passive outreach), and small cell sizes for some subgroups. The report lacks detailed representativeness adjustments, margin-of-error/p-value reporting, and deeper causal analysis. Overall the findings provide moderately strong descriptive support for the thesis about where people hear about and get involved in EA, but limitations mean conclusions about scaling or causal effectiveness of recruitment channels should be treated cautiously."
  },
  "PostExternalValidation": {
    "post_id": "r8XoHhKKzmQgxm2Lf",
    "emperical_claim_validation_score": 8,
    "validation_notes": "The post\u2019s empirical claims are well-supported by the primary source \u2014 the Rethink Priorities / EA Survey 2024 report on the EA Forum. Key numerical claims (e.g., \u2018first heard\u2019 percentages: Personal contact 17.9%, 80,000 Hours 15.8%; \u2018important for getting involved\u2019: 80,000 Hours 59.2%, personal contact 45%; outreach coding: 31.2% active, 24% passive, total \u224855.2%) appear verbatim in the published report and appendices. Year-over-year trend claims are consistent with Rethink Priorities\u2019 prior EA Survey posts (2020, 2022) and the authors explicitly report robustness checks (referrer exclusions) and a stated sample size (2,078) and caveats about representativeness. Main strengths: (a) transparent reporting of percentages, subgroup comparisons, and robustness checks in the primary report; (b) consistency with earlier EA Survey publications. Main weaknesses/limits: (a) the survey is non-probability/self-selected so representativeness of the broader EA population is uncertain (authors note this); (b) referral/referrer bias meaning some source percentages are sensitive to who referred respondents (authors ran exclusion robustness checks showing non-trivial effects); and (c) many subgroup comparisons rely on self-report and have varying sample sizes (confidence intervals sometimes wide). Because the claims are direct outputs from the official analysis and transparently caveated, I rate validation as strong but not \u201cexceptional\u201d given sampling and referral limitations.",
    "sources": [
      "EA Survey 2024: How People Get Involved in EA \u2014 Willem Sleegers & David_Moss (EA Forum, Mar 24, 2025). ([forum.effectivealtruism.org](https://forum.effectivealtruism.org/posts/r8XoHhKKzmQgxm2Lf/ea-survey-2024-how-people-get-involved-in-ea))",
      "EA Survey 2024: Demographics \u2014 Willem Sleegers & David_Moss (EA Forum, Feb 28, 2025) \u2014 includes sample size and representativeness caveats. ([forum.effectivealtruism.org](https://forum.effectivealtruism.org/posts/z4Wxd2dnTqDmFZrej/ea-survey-2024-demographics))",
      "EA Survey 2024: What Helps People Have an Impact and Connect with Other EAs \u2014 Willem Sleegers & David_Moss (EA Forum, Apr 14, 2025) \u2014 corroborating factor/impact findings. ([forum.effectivealtruism.org](https://forum.effectivealtruism.org/posts/uz2LGxrEovWSwAJ4q/ea-survey-2024-what-helps-people-have-an-impact-and-connect?utm_source=chatgpt.com))",
      "EA Survey 2022: How People Get Involved in EA (EA Forum / Rethink Priorities) \u2014 for year-over-year comparisons and trend context. ([forum.effectivealtruism.org](https://forum.effectivealtruism.org/s/FxFwhFG227F6FgnKk/p/aTSoxTcSjyBWem3Xz?utm_source=chatgpt.com))",
      "EA Survey 2020: How People Get Involved in EA \u2014 Rethink Priorities (original 2020 analysis and prior robustness-check approach). ([rethinkpriorities.org](https://rethinkpriorities.org/research-area/eas2020-how-people-get-involved-in-ea/?utm_source=chatgpt.com))"
    ]
  }
}