{
  "PostValue": {
    "post_id": "bpAtLByi335csJeNJ",
    "value_ea": 4,
    "value_humanity": 2,
    "explanation": "This is a modestly useful project for the EA/rationalist community but not foundational. A well-built visualization/estimation site could help outreach, education, and loosely aggregate community probabilistic judgments about long-term/x-risk trajectories, which would modestly influence funding discussions and public understanding. However, it is not load-bearing: the core decisions and research in AI safety, biosecurity, and longtermism do not depend on this tool. There are real risks (false precision, misleading defaults, oversimplified dependency structure) that could make it counterproductive if done poorly. For general humanity the direct impact is very small \u2014 a niche outreach/education tool rather than a lever that would change large-scale outcomes."
  },
  "PostRobustness": {
    "post_id": "bpAtLByi335csJeNJ",
    "robustness_score": 2,
    "actionable_feedback": "1) Missing/implicit model assumptions and uncertainty handling \u2014 make these explicit and give alternatives. Your idea (users enter per-year survival/extinction rates and you compute expected years/lives) rests on strong assumptions: stationarity or specified time-varying hazards, independence between years, and a particular mapping from survey answers to per-year rates. Those assumptions materially change results (especially with fat tails and structural shifts like fast AI progress). Actionable: add an explicit section (and UI toggle) listing the core assumptions; implement at least two aggregation modes (e.g. constant yearly hazard, time-varying hazard, and a scenario-based path), and show sensitivity analyses/credible intervals rather than single numbers. Explain how you transform survey answers into annualized probabilities and provide worked examples users can inspect.\n\n2) Risk-factor aggregation/causality is under-specified and risks producing misleading marginal effects. You say you want to show how removing a factor reduces overall extinction risk \u2014 but that requires modeling dependencies/conditional effects, not just summing or reweighting independent hazards. Actionable: either (A) simplify the first public release to only let users model a single aggregate hazard curve (avoid per-factor decomposition until you have a clear dependency model), or (B) build an explicit counterfactual module that asks users for conditional multipliers/correlations or lets them specify \u201cif X removed, overall hazard scales by Y\u201d (and document that this is a subjective counterfactual). Explicitly acknowledge that per-factor results are highly model-dependent.\n\n3) Communication, validation, and funder pitch need tightening. For general audiences the outputs (expected years/ lives left) are easy to misread or weaponize; for funders you\u2019ll need to show novelty, demand, and a plan for sourcing/curating defaults. Actionable: add a short \u2018how to interpret\u2019 panel/warning, include provenance for default numbers and a plan for community moderation of submitted estimates, compare your tool briefly to existing forecasting platforms (e.g. Metaculus/XPT/other x-risk work) and state the specific gap you fill. For funding apps, prepare a 1-paragraph elevator pitch that specifies target users, expected impact metrics, and an initial validation plan (usability testing + retrospective forecasts/calibration checks).",
    "improvement_potential": "Targets the core methodological and communication failures: unstated/strong modeling assumptions (stationarity, mapping survey answers to per-year hazards), dangerous per-factor decomposition without modeling dependencies, and weak funder/audience framing. Advice is actionable (UI toggles, scenarios, sensitivity/uncertainty, simplified first release, provenance/elevator pitch) and would substantially reduce the risk of misleading outputs or embarrassing mistakes. A near-complete critique \u2014 missing only a few nitpicks (e.g. heavy-tail/distributional issues, extinction definition/display choices) \u2014 so nearly essential to adopt."
  },
  "PostAuthorAura": {
    "post_id": "bpAtLByi335csJeNJ",
    "author_fame_ea": 1,
    "author_fame_humanity": 1,
    "explanation": "I cannot find evidence that 'Ville Sepp\u00e4l\u00e4' is a known figure in the EA/rationalist community or a publicly prominent author up to my 2024-06 cutoff. The name does not appear as a recognizable EA speaker, frequent contributor, or widely cited public intellectual; it may be a private person or pseudonym. If you have links or context (works, affiliations, platforms), I can reassess."
  },
  "PostClarity": {
    "post_id": "bpAtLByi335csJeNJ",
    "clarity_score": 8,
    "explanation": "Overall clear and well-structured: good TL;DR, wireframe link, defined audiences, and concrete requests for feedback/funding/collaborators. The main idea and intended functionality are easy to understand and the list of specific questions is helpful. Weaknesses: a few small typos and minor phrasing issues, some technical/design choices (e.g. \u201ctenfold increases\u201d, \u201ccondensed time scale\u201d, how yearly inputs map to expected years/lives, default-value strategy, and the 2026 coding timeline) are ambiguous and would benefit from brief clarifications; the ask for collaborators/funding could be tightened with more concrete next steps or asks."
  },
  "PostNovelty": {
    "post_id": "bpAtLByi335csJeNJ",
    "novelty_ea": 3,
    "novelty_humanity": 6,
    "explanation": "For an EA audience this is only mildly novel: the core ideas (survival curves, expected-years/expected-lives calculations, eliciting community probabilities, and the importance of dependencies between risks) are already discussed in Ord, XPT, Metaculus/GJO and other EA forecasting work. Packaging them into a public Shiny app and some UI choices (tenfold time bins, condensed time-scale visualisations, explicit marginal-reduction framing) are useful but incremental rather than original. For the general public it is more novel: an interactive, user-driven extinction-probability simulator that converts inputs into expected years/lives and highlights cumulative effects and interdependence of risks is not something most educated non\u2011EA readers have seen, so the concept would likely feel new and educational to that audience."
  },
  "PostInferentialSupport": {
    "post_id": "bpAtLByi335csJeNJ",
    "reasoning_quality": 5,
    "evidence_quality": 2,
    "overall_support": 3,
    "explanation": "Strengths: the proposal is coherent, targeted (two clear audiences), and shows some conceptual awareness (e.g. marginal contribution of risk factors, non-independence, different time scales). The design choices (visualization, downloadable data, R/Shiny) are plausible and appropriate. Weaknesses: the argument is high-level and speculative, with little demonstration of demand, user testing, or careful design work to avoid misinterpretation. Important methodological details are unspecified (definitions of extinction, how yearly probabilities are derived/validated, handling of deep uncertainty and dependencies, calibration and sensitivity analyses). Evidence: minimal \u2014 only a reference to XPT and a citation of Ord; no empirical validation, no pilot data, no user research, and no comparative analysis of existing tools. Overall: an interesting, potentially useful concept but currently under-supported and needing substantial methodological, empirical, and UX work before it would justify funding or strong endorsement."
  },
  "PostExternalValidation": {
    "post_id": "bpAtLByi335csJeNJ",
    "emperical_claim_validation_score": 7,
    "validation_notes": "Most of the post\u2019s empirical claims are verifiable and broadly accurate, but some are qualitative or normative rather than strictly empirical. Verified points: the Forecasting Research Institute\u2019s Existential\u2011Risk Persuasion Tournament (XPT, 2022) exists and asked long\u2011horizon questions (including extinction/expected\u2011year questions) and reported systematic differences between domain experts and \u201csuperforecasters\u201d; climate change is supported by empirical literature as a risk\u2011factor that increases likelihood of conflict (and so can amplify other catastrophic risks) rather than being an obvious direct extinction mechanism; R with Shiny and ggplot2 are standard, appropriate tools for an interactive visualization site; and the actuarial/survival\u2011function approach the author describes (summing survival probabilities to get expected years left/expected life\u2011years) is a standard method. Less precise / partially supported claims: the claim that \u201clonger time scales have not been paid too much attention\u201d is partly true in that many empirical forecasting efforts focus on nearer horizons or on particular risks, although there is a growing (but still relatively small) literature and notable long\u2011term syntheses (e.g., Ord, Bostrom) \u2014 bibliometric work shows the field is expanding but still uneven across topics. The poster\u2019s suggestion to draw defaults from XPT is reasonable (XPT provides usable long\u2011horizon forecasts) but should be used with caution because AI capabilities and other risk landscapes have changed since 2022. Overall: the post is well\u2011grounded, with mostly accurate empirical claims and reasonable citations to existing work, but some claims are qualitative and hinge on definitional choices (e.g., definitions of \u201cextinction\u201d vs. \u201cexistential catastrophe\u201d) and on rapidly evolving domains (AI), so treating defaults as provisional is important.",
    "sources": [
      "Forecasting Research Institute \u2014 XPT (Existential Risk Persuasion Tournament) project page (ForecastingResearch.org/xpt) \u2014 description and links to the 2022 tournament and report.",
      "Forecasting Research Institute \u2014 \u2018Results from the 2022 Existential Risk Persuasion Tournament\u2019 (news post, July 2023) \u2014 summary of median expert vs. superforecaster forecasts and tournament design.",
      "EA Forum post: 'Results from the Existential Risk Persuasion Tournament' (Forecasting Research Institute summary on forum.effectivealtruism.org) \u2014 community writeup / discussion of XPT results.",
      "Hsiang S.M., Burke M., Miguel E. (2013). Quantifying the Influence of Climate on Human Conflict. Science 341(6151):1235367 \u2014 meta\u2011analysis showing causal links between temperature/rainfall deviations and increased interpersonal/intergroup conflict.",
      "Toby Ord (2020). The Precipice: Existential Risk and the Future of Humanity (Chapters on combining risks and 'risk factors', e.g., Chapter 6/pp.165\u2013180 and risk factors discussion around p.175).",
      "RStudio / Shiny documentation and GitHub (rstudio/shiny) \u2014 Shiny is a standard framework for building interactive web apps in R (suitable for this project).",
      "ggplot2 documentation (ggplot2.tidyverse.org) \u2014 ggplot2 is the standard R graphics library the author proposes to use.",
      "Survival analysis / actuarial standard formulas (e.g., Wikipedia: 'Survival analysis' and actuarial references) \u2014 expected future lifetime equals integral/sum of the survival function, which underlies the author\u2019s expected\u2011years calculation.",
      "Copernicus ESD 2025 bibliometric review: 'The state of global catastrophic risk research: a bibliometric review' (Jehn et al., 2025) \u2014 shows the field\u2019s growth and topical distribution, supporting the claim that the literature is growing but uneven (many clusters focus on particular risk drivers).",
      "OpenAI GPT\u20114 Technical Report (March 2023) and related press coverage \u2014 evidence of substantive AI capability progress since 2022, supporting the author\u2019s caution that AI risk estimates from older studies may need updating."
    ]
  }
}